# 2025-07-21 地下水位预测项目代码总结文档

## 项目概述

本项目是一个地下水位时序预测的综合性机器学习/深度学习框架，实现了统计学、机器学习和深度学习三大类预测方法的对比分析。项目名称为 `Groundwater_Level_Prediction_ML_DL`，旨在为地下水位预测提供可复现的跨范式基准测试平台。

## 项目结构

```
├── database/                           # 数据文件夹
│   ├── plots/                          # 数据清洗后的可视化图表
│   ├── ZoupingCounty_gwl_data*.xlsx    # 邹平县地下水位原始数据
│   ├── ZoupingCounty_gwl_filled.xlsx   # 最终清洗插值后的数据
│   └── 长序列的两口井先不测试.xlsx      # 长序列数据（暂不使用）
├── model/                              # 深度学习模型定义
│   ├── model.py                        # GRU、LSTM、Transformer模型实现
│   └── __pycache__/                    # Python缓存文件
├── results/                            # 训练结果输出目录
│   ├── multi_wells_3dl/                # 多井位深度学习结果
│   ├── single_well_transformer/        # 单井位Transformer结果
│   └── *.pt                           # 训练好的模型权重文件
├── cursor-chat/                        # 项目开发日志
├── DataCleaning.py                     # 数据清洗脚本
├── train_3DL_multi_wells.py           # 多井位深度学习训练（并行）
├── train_3DL_single_well.py           # 单井位深度学习训练
├── train_arima_multi_wells.py         # 多井位ARIMA训练（并行）
├── train_arima_single_well.py         # 单井位ARIMA训练
├── train_ml_multi_wells.py            # 多井位机器学习训练（并行）
├── train_ml_single_well.py            # 单井位机器学习训练
├── run_all_wells_*.sh                 # 批量训练脚本
├── requirements.txt                    # 依赖包列表
└── README.md                          # 项目说明文档（详细的学术级文档）
```

## 核心功能模块

### 1. 数据处理模块 (`DataCleaning.py`)

**功能**：
- 读取原始Excel地下水位数据
- 自动生成井位列名（格式：`<中文名称>-井<n>`）
- 日期解析和数据清洗（支持两种时间格式）
- 截取有效时间区间（至2019-10-01）
- 线性/样条插值填补缺失值
- 生成双子图对比（原始vs处理后）

**关键特性**：
- 支持两种插值方法：线性插值和样条插值
- 自动处理重复列名问题
- 生成详细的可视化对比图表
- 中文字体支持和警告过滤
- 自动创建输出目录结构

### 2. 统计学方法（ARIMA建模）

#### 2.1 单井位ARIMA (`train_arima_single_well.py`)
**核心特点**：
- **自动差分**：通过ADF检验和Ljung-Box检验自动确定差分阶数
- **网格搜索**：AIC准则驱动的(p,q)参数优化
- **详细日志**：完整的建模过程记录
- **结果保存**：JSON格式详细结果 + Excel汇总表

#### 2.2 多井位ARIMA (`train_arima_multi_wells.py`)
**并行处理特性**：
- **ProcessPoolExecutor**：多进程并行建模
- **错误处理**：单井位失败不影响整体流程
- **批量可视化**：自动生成概览图和单井位详细图
- **灵活展示**：支持指定井位序号生成图表

**技术细节**：
- 差分条件：ADF ≤ 0.05 且 Ljung-Box ≤ 0.05
- 支持最大差分阶数限制
- 原始尺度预测，保持物理可解释性

### 3. 机器学习方法（梯度提升树）

#### 3.1 单井位机器学习 (`train_ml_single_well.py`)
**支持的算法**：
- **XGBoost**：梯度提升决策树
- **LightGBM**：轻量级梯度提升机

#### 3.2 多井位机器学习 (`train_ml_multi_wells.py`)
**并行处理架构**：
- 每个井位 × 每个模型的任务并行化
- 统一的结果收集和汇总
- 自动模型保存（joblib格式）

**超参数配置亮点**：
```python
# XGBoost配置
XGBRegressor(
    n_estimators=400,      # 平衡性能与过拟合
    max_depth=6,           # 适中的树深度
    learning_rate=0.03,    # 较小学习率提升泛化
    subsample=0.8,         # 行采样防过拟合
    colsample_bytree=0.8,  # 列采样增强鲁棒性
    objective="reg:squarederror",
    tree_method="hist",    # 直方图算法，内存友好
    random_state=42
)

# LightGBM配置
LGBMRegressor(
    n_estimators=800,      # 更多弱学习器
    max_depth=-1,          # 用num_leaves控制复杂度
    learning_rate=0.03,
    subsample=0.8,
    colsample_bytree=0.8,
    objective="l2",
    random_state=42
)
```

### 4. 深度学习方法（神经网络）

#### 4.1 单井位深度学习 (`train_3DL_single_well.py`)
**支持的架构**：
- **GRU**：门控循环单元，轻量级门控机制
- **LSTM**：长短期记忆网络，显式细胞状态
- **Transformer**：自注意力编码器，全局上下文建模

#### 4.2 多井位深度学习 (`train_3DL_multi_wells.py`)
**高级并行处理**：
- 支持选择性模型训练（--models参数）
- 灵活的可视化控制（--show_wells参数）
- 完整的训练状态监控和错误处理

**创新技术**：
- **导数感知损失**：`L = MSE(值) + α·MSE(一阶差分)`
- **梯度裁剪**：防止梯度爆炸（‖g‖₂ ≤ 1）
- **AdamW优化器**：权重衰减正则化
- **位置编码**：Transformer的时序位置信息

**模型架构特色**：
```python
# 复合损失函数
def loss_with_derivative(pred, true, alpha):
    mse_val = F.mse_loss(pred, true)
    if pred.size(1) < 2:  # 单步预测，无差分
        return mse_val
    d_pred = pred[:, 1:] - pred[:, :-1]
    d_true = true[:, 1:] - true[:, :-1]
    mse_diff = F.mse_loss(d_pred, d_true)
    return mse_val + alpha * mse_diff

# Transformer位置编码
class PositionalEncoding(nn.Module):
    def __init__(self, d_model, max_len=5000):
        super().__init__()
        encoding = torch.zeros(max_len, d_model)
        positions = torch.arange(max_len).float().unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float()
                           * -(math.log(10000.0) / d_model))
        encoding[:, 0::2] = torch.sin(positions * div_term)
        encoding[:, 1::2] = torch.cos(positions * div_term)
        self.register_buffer("encoding", encoding.unsqueeze(0))
```

### 5. 模型定义模块 (`model/model.py`)

**架构实现**：
- **GeneratorGRU**：简洁的GRU实现，包含Dropout正则化
- **GeneratorLSTM**：增强的LSTM，集成深度可分离卷积
- **GeneratorTransformer**：完整的Transformer编码器，支持因果掩码

**技术亮点**：
```python
# LSTM中的深度可分离卷积
self.depth_conv = nn.Conv1d(input_size, input_size, kernel_size=3,
                           padding=1, groups=input_size)
self.point_conv = nn.Conv1d(input_size, input_size, kernel_size=1)

# Transformer的因果掩码生成
@staticmethod
def _generate_square_subsequent_mask(seq_len, device):
    return torch.triu(torch.ones(seq_len, seq_len,
                                dtype=torch.bool, device=device), 1)
```

## 批量处理系统

### 1. Shell脚本批量训练
#### ARIMA批量训练 (`run_all_wells_arima.sh`)
- 遍历23口井位（第2-24列）
- 自动创建结果子目录
- 生成原始序列和差分序列对比图

#### 深度学习批量训练 (`run_all_wells_3DL.sh`)
- 支持GRU、LSTM、Transformer三种架构
- 包含损失曲线、预测图表、指标文件
- 最佳模型权重自动保存

### 2. Python内置并行处理系统

#### 多井位并行训练架构
所有多井位训练脚本都采用了统一的并行处理架构：

**核心特性**：
- **ProcessPoolExecutor**：多进程并行，充分利用多核CPU
- **任务分发**：每个井位×每个模型作为独立任务
- **错误隔离**：单个任务失败不影响整体流程
- **结果汇总**：自动收集和整理所有结果

**命令行参数**：
```bash
# 并行处理控制
--parallel              # 启用并行处理
--n_jobs 4             # 并行进程数（默认CPU核心数的一半）

# 结果展示控制
--show_wells "2,4,6"   # 指定展示的井位序号
--models "transformer" # 指定训练的模型（深度学习）

# 数据范围控制
--start_col 1          # 起始井位列序号
--end_col 3            # 结束井位列序号（-1表示全部）
```

#### 结果输出结构
每个多井位训练都会生成完整的结果目录：
```
results/multi_wells_[method]/
├── multi_wells_[method]_results.json      # 详细结果JSON
├── multi_wells_[method]_summary.xlsx      # Excel汇总表
├── multi_wells_[method]_summary.csv       # CSV汇总表
├── pred_vs_true_[model]_[well].png       # 单井位预测图
├── loss_curve_[model]_[well].png         # 训练损失曲线（深度学习）
└── multi_wells_[method]_overview.png     # 多井位概览图
```

## 数据接口规范

**输入格式**：
- Excel/CSV文件，每列代表一个监测井
- 可选的`日期`列作为时间索引
- 支持不规则时间间隔（需预处理）

**预处理流程**：
- Min-Max归一化至[0,1]区间
- 滑动窗口特征构造
- 训练/测试集划分
- 自动反归一化用于指标计算

## 评估指标体系

**统一指标**：
- **RMSE**：均方根误差
- **MAE**：平均绝对误差  
- **MAPE**：平均绝对百分比误差
- **MSE**：均方误差

**可视化输出**：
- 训练/测试预测对比图
- 损失收敛曲线（深度学习）
- 原始vs差分序列图（ARIMA）

## 技术栈

**核心依赖**：
```
torch>=2.0          # 深度学习框架
pandas              # 数据处理
numpy               # 数值计算
scikit-learn        # 机器学习工具
matplotlib          # 可视化
xgboost>=1.7        # 梯度提升
lightgbm>=4.0       # 轻量级GBDT
statsmodels         # 统计建模
openpyxl            # Excel读写
joblib              # 模型序列化
```

## 使用示例

### 单井位建模
```bash
# 1. 单井位ARIMA自动差分建模
python train_arima_single_well.py \
  --data_path database/ZoupingCounty_gwl_filled.xlsx \
  --well_col 4 --max_p 4 --max_q 4 --max_d 2 \
  --train_ratio 0.8

# 2. 单井位机器学习建模
python train_ml_single_well.py \
  --data_path database/ZoupingCounty_gwl_filled.xlsx \
  --well_col 4 --model lgbm \
  --window_size 24 --pred_len 4 --train_ratio 0.8

# 3. 单井位深度学习建模
python train_3DL_single_well.py \
  --data_path database/ZoupingCounty_gwl_filled.xlsx \
  --well_col 4 --model transformer \
  --window_size 24 --pred_len 4 --epochs 100 \
  --lr 1e-3 --alpha 0.5 --batch_size 16
```

### 多井位并行建模
```bash
# 1. 多井位ARIMA并行建模（井位1-3，使用4个进程）
python train_arima_multi_wells.py \
  --data_path database/ZoupingCounty_gwl_filled.xlsx \
  --start_col 1 --end_col 3 \
  --parallel --n_jobs 4 \
  --show_wells "1,2,3"

# 2. 多井位机器学习并行建模
python train_ml_multi_wells.py \
  --data_path database/ZoupingCounty_gwl_filled.xlsx \
  --start_col 1 --end_col 5 \
  --window_size 24 --pred_len 4 \
  --parallel --n_jobs 4

# 3. 多井位深度学习并行建模（只训练Transformer）
python train_3DL_multi_wells.py \
  --data_path database/ZoupingCounty_gwl_filled.xlsx \
  --start_col 1 --end_col 3 \
  --models "transformer" \
  --window_size 24 --pred_len 4 --epochs 100 \
  --parallel --n_jobs 2 \
  --show_wells "1,3"

# 4. 多井位深度学习（训练所有模型）
python train_3DL_multi_wells.py \
  --data_path database/ZoupingCounty_gwl_filled.xlsx \
  --start_col 1 --end_col 5 \
  --models "all" \
  --parallel --n_jobs 4
```

### Shell脚本批量训练
```bash
# 传统批量训练脚本（适用于集群环境）
bash run_all_wells_arima.sh      # ARIMA批量训练
bash run_all_wells_3DL.sh        # 深度学习批量训练
```

### 数据预处理
```bash
# 数据清洗和插值处理
python DataCleaning.py
# 输出：database/ZoupingCounty_gwl_filled.xlsx
# 可视化：database/plots/[井位名称].png
```

## 项目亮点

### 1. 方法论完整性
- **三大范式覆盖**：统计学（ARIMA）、机器学习（XGBoost/LightGBM）、深度学习（GRU/LSTM/Transformer）
- **统一评估标准**：所有方法使用相同的RMSE、MAE、MAPE指标
- **一致的数据流**：统一的滑动窗口构造和归一化处理
- **可复现设置**：固定随机种子和详细的超参数记录

### 2. 技术创新亮点

#### 2.1 导数感知损失函数
```python
# 创新的复合损失，同时优化预测值和变化趋势
L = MSE(预测值, 真实值) + α × MSE(预测差分, 真实差分)
```
- 促进时序预测的平滑性和趋势一致性
- 对多步预测特别有效
- α参数可调节平滑程度

#### 2.2 自动差分ARIMA
- **智能差分判定**：结合ADF检验和Ljung-Box检验
- **避免过度差分**：防止信号损失和白噪声化
- **原始尺度预测**：保持物理意义的可解释性

#### 2.3 深度可分离卷积LSTM
```python
# 在LSTM中集成卷积特征提取
self.depth_conv = nn.Conv1d(input_size, input_size, kernel_size=3,
                           padding=1, groups=input_size)
self.point_conv = nn.Conv1d(input_size, input_size, kernel_size=1)
```
- 增强局部特征提取能力
- 减少参数量，提高训练效率

### 3. 工程化架构

#### 3.1 高效并行处理
- **多进程架构**：ProcessPoolExecutor实现真正的并行计算
- **任务粒度优化**：每个井位×模型作为独立任务
- **容错机制**：单任务失败不影响整体流程
- **资源管理**：自动调节进程数，避免系统过载

#### 3.2 完整的结果管理系统
```
# 每个训练任务的完整输出
├── [method]_results_[well].json        # 详细结果（可编程访问）
├── [method]_summary_[well].xlsx        # 人类可读汇总
├── pred_vs_true_[method]_[well].png   # 预测对比图
├── loss_curve_[method]_[well].png     # 训练曲线（深度学习）
└── multi_wells_[method]_overview.png  # 多井位概览
```

#### 3.3 灵活的可视化控制
- **选择性展示**：`--show_wells "1,3,5"` 只为指定井位生成图表
- **模型选择**：`--models "transformer,lstm"` 只训练指定模型
- **批量概览**：自动生成多井位对比图

### 4. 代码质量与可维护性

#### 4.1 统一的错误处理
```python
# 每个建模函数都有完整的异常处理
try:
    # 建模逻辑
    result['success'] = True
except Exception as e:
    result['error_msg'] = f"井位 {well_name} 建模过程出错: {str(e)}"
    result['success'] = False
```

#### 4.2 详细的日志系统
- **分级日志**：INFO级别记录关键进展，WARNING记录异常
- **进度追踪**：实时显示并行任务完成情况
- **性能统计**：自动计算和展示各模型的平均性能

#### 4.3 模块化设计
- **模型工厂模式**：`get_model(name, params)` 统一模型创建
- **指标计算统一**：`metrics(y_true, y_pred)` 处理NaN值和异常情况
- **数据处理管道**：`create_sliding_window()` 可复用的特征工程

### 5. 扩展性设计

#### 5.1 预留的扩展接口
```python
# 支持多变量输入的滑动窗口（当前为单变量）
def create_sliding_window(series, window, pred_len=1, features=None):
    # 可扩展为多通道输入
    pass

# 支持概率预测的损失函数
def quantile_loss(pred, true, quantiles=[0.1, 0.5, 0.9]):
    # 分位数回归损失
    pass
```

#### 5.2 配置驱动的架构
- 所有超参数通过命令行参数控制
- 支持配置文件批量设置（预留）
- 模型架构参数化，便于调优

## 应用场景

**适用领域**：
- 地下水资源管理
- 水文时序预测
- 环境监测数据分析
- 时序建模方法对比研究

**扩展方向**：
- 多变量输入（降水、抽水量等）
- 概率预测（分位数回归）
- 时序交叉验证
- 贝叶斯集成方法

## 开发历程

根据cursor-chat记录，项目经历了以下主要开发阶段：
1. **2025-07-08**：时序预测建模框架搭建
2. **2025-07-09**：批量训练脚本开发
3. **持续优化**：模型架构和损失函数改进

---

*本文档总结了地下水位预测项目的完整技术架构和实现细节，为后续开发和应用提供参考。*